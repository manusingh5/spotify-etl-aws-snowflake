# ğŸ§ Spotify Data Pipeline using AWS & Snowflake

## ğŸ“Œ Project Overview
This project demonstrates an end-to-end cloud-based data pipeline to extract, transform, and load Spotify data using AWS services and Snowflake.  
It automates data flow from Spotify API to Snowflake via S3, AWS Glue, and Snowpipe.

---

## ğŸ§° Tools & Technologies Used

- **AWS S3** â€“ Raw and transformed data storage  
- **AWS Lambda** â€“ Data extraction using Spotify API  
- **AWS Glue** â€“ Data transformation with PySpark  
- **Amazon CloudWatch** â€“ Scheduled triggers for Lambda  
- **Snowflake** â€“ Cloud data warehouse  
- **Snowpipe** â€“ Real-time ingestion from S3 to Snowflake  
- 

---## ğŸ“‚ S3 Folder Structure
s3://spotify-etl-glue-project/
â”œâ”€â”€ raw_data/
â”‚ â”œâ”€â”€ to_processed/ â† Raw JSON files from Lambda (initial)
â”‚ â””â”€â”€ processed/ â† Moved after transformation (archived)
â”‚
â”œâ”€â”€ transformed/
â”‚ â”œâ”€â”€ songs_data/ â† Cleaned song data
â”‚ â”œâ”€â”€ artist_data/ â† Cleaned artist data
â”‚ â””â”€â”€ album_data/ â† Cleaned album data

### ğŸ“‹ Folder Descriptions

| S3 Folder Path                          | Description                                      |
|----------------------------------------|--------------------------------------------------|
| `raw_data/to_processed/`               | Raw JSON from Lambda (before Glue processes it)  |
| `raw_data/processed/`                  | Archived after Glue processing (safe backup)     |
| `transformed/songs_data/`              | Transformed songs data (ready for Snowpipe)      |
| `transformed/artist_data/`             | Transformed artist metadata                      |
| `transformed/album_data/`              | Transformed album metadata                       |




ğŸ“ After Glue processing, raw files are archived from `to_processed/` to `processed/` for future reference and debugging.

---

## ğŸ“ˆ Architecture Diagram

Architecture---(architecture.png)

---

## ğŸ§  Workflow

1. **CloudWatch** triggers Lambda daily  
2. **Lambda** extracts raw Spotify data â†’ saves in `s3://spotify-etl-glue-project/raw_data/processed/`
3. **AWS Glue** transforms raw data â†’ writes cleaned data to:
 s3://spotify-etl-glue-project/transformed/
â”œâ”€â”€ songs_data/
â”œâ”€â”€ artist_data/
â””â”€â”€ album_data/

4. **Snowpipe** automatically ingests data from `transformed/` into Snowflake staging tables
5. Final tables are updated via SQL in Snowflake


---

## ğŸ“‚ Folder Structure in GitHub Repo

spotify-etl-aws-snowflake/
â”‚
â”œâ”€â”€ lambda_function/
â”‚ â””â”€â”€ lambda_handler.py
â”‚
â”œâ”€â”€ glue_jobs/
â”‚ â””â”€â”€ spotify_etl_glue_job.py
â”‚
â”œâ”€â”€ snowflake/
â”‚ â”œâ”€â”€ create_tables.sql
â”‚ â”œâ”€â”€ create_pipes.sql
â”‚ â””â”€â”€ stage_and_integration.sql
â”‚
â”œâ”€â”€ architecture.png
â””â”€â”€ README.md


---

## ğŸ™‹â€â™€ï¸ Role & Contribution

I independently built this entire pipeline:
- Developed Lambda function to call Spotify API
- Designed S3 folder structure and raw-to-clean data flow
- Created PySpark Glue jobs for transformation
- Configured Snowpipe for real-time loading into Snowflake
- Managed full AWS â†’ Snowflake 

---

## ğŸ“¬ Contact

Created by **Manu Singh**  
ğŸ”— LinkedIn- https://www.linkedin.com/in/manu-singh-a68776ab/  
ğŸ“§ your- sinhmanu0508@gmail.com










